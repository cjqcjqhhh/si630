{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI630 Homework 2: Word2vec Vector Analysis (For Part 3)\n",
    "\n",
    "*Important Note:* Start this notebook only after you've gotten your word2vec model up and running!\n",
    "\n",
    "Many NLP packages support working with word embeddings. In this notebook you can work through the various problems assigned in Task 3. We've provided the basic functionality for loading word vectors using [Gensim](https://radimrehurek.com/gensim/models/keyedvectors.html), a good library for learning and using word vectors, and for working with the vectors. \n",
    "\n",
    "One of the fun parts of word vectors is getting a sense of what they learned. Feel free to explore the vectors here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"third_model\"\n",
    "word_vectors = KeyedVectors.load_word2vec_format('./models/'+model_name+'.kv', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.803966  ,  0.20739706, -0.41470504, -0.09618309,  0.15361309,\n",
       "        0.36841783, -0.21240279,  0.01897331, -0.09516799, -0.29754043,\n",
       "       -0.27828205, -0.05730286,  0.08532567,  0.191788  , -0.6630302 ,\n",
       "       -0.37582618,  0.17940123, -0.43394163, -0.59503525,  0.77354383,\n",
       "       -0.4571756 ,  0.0418206 ,  0.4222303 , -0.24021253,  0.2567409 ,\n",
       "        0.18184762,  0.2423835 ,  0.13162646,  0.14234862, -0.13687187,\n",
       "        0.06895836,  0.3538237 ,  0.01597746, -0.14195429, -0.40593222,\n",
       "       -0.47744456, -0.19720761,  0.21820286,  0.2837015 ,  0.24548618,\n",
       "        0.2045187 , -0.63596004, -0.03282333,  0.4831505 , -0.44626796,\n",
       "        0.13517477,  0.2952347 , -0.0601838 , -0.31692913, -0.5239965 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('articles', 0.9607430100440979),\n",
       " ('papers', 0.9235630035400391),\n",
       " ('novels', 0.9147697687149048),\n",
       " ('poems', 0.9087007641792297),\n",
       " ('chapters', 0.9040026664733887),\n",
       " ('monographs', 0.9021276235580444),\n",
       " ('works', 0.9005582332611084),\n",
       " ('essays', 0.8988243341445923),\n",
       " ('publications', 0.8987964391708374),\n",
       " ('stories', 0.8964657187461853)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(a, b, c):\n",
    "    return word_vectors.most_similar(positive=[b, c], negative=[a])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queen'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('man', 'woman', 'king')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similar word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bread</td>\n",
       "      <td>vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>physics</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>encourage</td>\n",
       "      <td>enhance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>revenue</td>\n",
       "      <td>tax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covid</td>\n",
       "      <td>pandemic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>genetic</td>\n",
       "      <td>protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>supernova</td>\n",
       "      <td>gently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oxidation</td>\n",
       "      <td>stucco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>serendipity</td>\n",
       "      <td>weeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>concession</td>\n",
       "      <td>debtors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word similar word\n",
       "0        bread   vegetables\n",
       "1      physics    chemistry\n",
       "2    encourage      enhance\n",
       "3      revenue          tax\n",
       "4        covid     pandemic\n",
       "5      genetic      protein\n",
       "6    supernova       gently\n",
       "7    oxidation       stucco\n",
       "8  serendipity      weeting\n",
       "9   concession      debtors"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [\n",
    "    \"bread\",\n",
    "    \"physics\",\n",
    "    \"encourage\",\n",
    "    \"revenue\",\n",
    "    \"covid\",\n",
    "    \"genetic\",\n",
    "    \"supernova\",\n",
    "    \"oxidation\",\n",
    "    \"serendipity\",\n",
    "    \"concession\"\n",
    "]\n",
    "\n",
    "most_similar_word_list = []\n",
    "\n",
    "for word in word_list:\n",
    "    most_similar_word_list.append(word_vectors.similar_by_word(word)[0][0])\n",
    "    \n",
    "word_df = pd.DataFrame({\n",
    "    \"word\": word_list,\n",
    "    \"similar word\": most_similar_word_list\n",
    "})\n",
    "\n",
    "word_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table shown above (from the most common words to rare ones), we can find out the facts that:\n",
    "\n",
    "+ For those commonly used words (0 - 6), we can easily figure out the relationship between the target word and its most similar word. For example, physics and chemistry are both categoried as natural sciences.\n",
    "\n",
    "+ However, for those rare words, we can see that the model works not so well on them like connecting the oxidation with stucco. We can hardly figure out relationship in bwtween. It may results from the lack of training examples.\n",
    "\n",
    "(The whole list of similar words for each target word are shown for your reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vegetables', 0.9718700647354126),\n",
       " ('toxic', 0.970106840133667),\n",
       " ('acrylic', 0.9676809906959534),\n",
       " ('molecules', 0.9675472974777222),\n",
       " ('crude', 0.9674468636512756),\n",
       " ('healing', 0.9667180776596069),\n",
       " ('gravity', 0.9660497307777405),\n",
       " ('liquid', 0.9651873707771301),\n",
       " ('proteins', 0.9649662375450134),\n",
       " ('humans', 0.9645667672157288)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"bread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chemistry', 0.992280125617981),\n",
       " ('biology', 0.9870692491531372),\n",
       " ('engineering', 0.981624960899353),\n",
       " ('mathematics', 0.9779875874519348),\n",
       " ('economics', 0.9759252667427063),\n",
       " ('physiology', 0.9699663519859314),\n",
       " ('psychology', 0.9684190154075623),\n",
       " ('geology', 0.9681183099746704),\n",
       " ('sociology', 0.9652984738349915),\n",
       " ('electrical', 0.962410569190979)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"physics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enhance', 0.9857335686683655),\n",
       " ('analyze', 0.9803969264030457),\n",
       " ('aims', 0.9803727269172668),\n",
       " ('generate', 0.9786515235900879),\n",
       " ('encouraging', 0.9777085185050964),\n",
       " ('integrate', 0.9749067425727844),\n",
       " ('preserve', 0.9743477702140808),\n",
       " ('engage', 0.9742167592048645),\n",
       " ('introduce', 0.9726227521896362),\n",
       " ('explore', 0.9710420966148376)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"encourage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tax', 0.953637421131134),\n",
       " ('expenditures', 0.9432281255722046),\n",
       " ('aircraft', 0.941349446773529),\n",
       " ('statewide', 0.9402140974998474),\n",
       " ('implementation', 0.9333816766738892),\n",
       " ('arbitration', 0.9323774576187134),\n",
       " ('units', 0.9320067167282104),\n",
       " ('resolution', 0.9312455654144287),\n",
       " ('expenditure', 0.9311120510101318),\n",
       " ('task', 0.9306795597076416)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"revenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pandemic', 0.9395113587379456),\n",
       " ('coronavirus', 0.9303358197212219),\n",
       " ('deadline', 0.8798041343688965),\n",
       " ('expire', 0.8621783256530762),\n",
       " ('hayemaker', 0.8589552640914917),\n",
       " ('nitro', 0.8506273031234741),\n",
       " ('himara', 0.84943687915802),\n",
       " ('ttff', 0.8483490943908691),\n",
       " ('pipa', 0.8479142785072327),\n",
       " ('tuesday', 0.8475530743598938)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('protein', 0.9793424606323242),\n",
       " ('linear', 0.9696540832519531),\n",
       " ('functional', 0.9683409929275513),\n",
       " ('mechanisms', 0.9682909846305847),\n",
       " ('neural', 0.9656184315681458),\n",
       " ('materials', 0.9642196297645569),\n",
       " ('devices', 0.9641343951225281),\n",
       " ('processes', 0.9639464020729065),\n",
       " ('fluid', 0.9637303352355957),\n",
       " ('differential', 0.961711049079895)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"genetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gently', 0.9779091477394104),\n",
       " ('silly', 0.9743908047676086),\n",
       " ('fancy', 0.9738282561302185),\n",
       " ('foolish', 0.9699468612670898),\n",
       " ('donkey', 0.9692879915237427),\n",
       " ('accents', 0.9675639271736145),\n",
       " ('sincerity', 0.9652719497680664),\n",
       " ('phrases', 0.9646726250648499),\n",
       " ('melt', 0.9645059108734131),\n",
       " ('masculine', 0.9643701910972595)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"supernova\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stucco', 0.9436200261116028),\n",
       " ('rectifier', 0.9348612427711487),\n",
       " ('Ï„', 0.9347659945487976),\n",
       " ('individuation', 0.9324919581413269),\n",
       " ('semigroups', 0.9321315288543701),\n",
       " ('prophetic', 0.9318394064903259),\n",
       " ('transformer', 0.9317874908447266),\n",
       " ('denoting', 0.9300829768180847),\n",
       " ('horizontal', 0.930073082447052),\n",
       " ('deformation', 0.9283044338226318)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"oxidation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weeting', 0.98467618227005),\n",
       " ('woz', 0.983461320400238),\n",
       " ('ableton', 0.9830171465873718),\n",
       " ('bhavana', 0.9825843572616577),\n",
       " ('lukens', 0.9821453094482422),\n",
       " ('preethi', 0.9817216992378235),\n",
       " ('gecenin', 0.9816479682922363),\n",
       " ('cantus', 0.9809957146644592),\n",
       " ('tn5', 0.9809512495994568),\n",
       " ('kelebek', 0.9806206226348877)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"serendipity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('debtors', 0.9847534894943237),\n",
       " ('rioting', 0.9748736023902893),\n",
       " ('queue', 0.9741414785385132),\n",
       " ('occupancy', 0.9740566611289978),\n",
       " ('uninhabited', 0.9738625884056091),\n",
       " ('modernise', 0.9724675416946411),\n",
       " ('hispania', 0.9724375605583191),\n",
       " ('expressly', 0.972412109375),\n",
       " ('lithuanians', 0.9723716974258423),\n",
       " ('elephantine', 0.9722658395767212)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"concession\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sword - attack + defense = non\n",
      "jump - up + down = pistol\n",
      "water - liquid + solid = wide\n",
      "january - one + six = june\n",
      "earth - human + sun = devil\n"
     ]
    }
   ],
   "source": [
    "def print_get_analogy(a, b, c):\n",
    "    print(f\"{b} - {a} + {c} = {get_analogy(a, b, c)}\")\n",
    "\n",
    "# print_get_analogy('man', 'king', 'woman') # example\n",
    "print_get_analogy('attack', 'sword', 'defense')\n",
    "print_get_analogy('up', 'jump', 'down')\n",
    "print_get_analogy('liquid', 'water', 'solid')\n",
    "print_get_analogy('one', 'january', 'six')\n",
    "print_get_analogy('human', 'earth', 'sun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the five examples above, we can see that not all equations work the same as my thought (for the first 3 examples). For example, I orginally think that jump - up + down will lead to a \"fall\". However, it does not work. But for the last two examples, it makes sense in to some extent.\n",
    "\n",
    "From my point of view, it is because the model is not trained well enough to explore the similarity in between. We may need more training data and further training to reach a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
